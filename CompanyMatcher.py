# -*- coding: utf-8 -*-
"""Textual Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YQy9L4bYQNDL32HRDM9Wzr5CvNk1Jymk

**Textual Analysis**

This code is used to conduct text analysis, seeking matches between two documents: the company's full name and its relative information.

date: 02/13/2025

Reference Package:
1.fuzzywuzzy
2.python-Levenshtein
3.nltk

Words Documents:
nltk.wordnet, nltk.punkt, nltk.stopwords

Matching Process:

(1)Import Data

(2)Clean Data:
    
    (a)Remove redundant substrings such as "inc." to simplify computation.
    
    (b)Convert all characters to lowercase.
    
    (c)Perform string matching.

(3)Output Results.
"""

#! pip install fuzzywuzzy
#! pip install python-Levenshtein

import nltk
nltk.download('wordnet')
nltk.download('punkt')
nltk.download('stopwords')

import pandas as pd
from fuzzywuzzy import process
import re
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords

# Load datasets
data1 = pd.read_csv("Data1_Sample.csv",encoding='utf-8',header=0,sep=None)
data2 = pd.read_csv("Data2_Sample.csv",encoding='utf-8',header=0,sep=None)

# Additional legal identifiers and abbreviations
legal_identifiers = ['corp', 'corporation', 'inc', 'plc', 'ltd', 'llc', 'llp', 'gmbh', 'ag', 'sa', 'nv', 'bv', 'sarl','l.l.c.','co.','co','co.,','llc','corporation','incorporated','lp','company,','company','cos.''.com','foundation','limited','national association','n.a.','companies','companies,']

# Function to preprocess company names
def preprocess_company_name(name):
    # Convert to lowercase
    name = name.lower()
    # Construct regular expression pattern to match legal identifiers and their following strings,
    # including patterns like (NYSE:ESTC)
    legal_pattern = r'\b(?:' + '|'.join(legal_identifiers) + r')\b\.?\s*(?:\([^)]*\))?(?:\([^)]*\))?$'
    # Remove common legal identifiers and their following strings, and punctuations
    name = re.sub(legal_pattern, '', name, flags=re.IGNORECASE)
    # Remove parentheses and their content
    name = re.sub(r'\([^)]*\)', '', name)
    # Remove 'cos.' and '.com' strings
    name = re.sub(r'cos\.|\.com', '', name)
    # Remove punctuations and special characters
    name = re.sub(r'[^\w\s]', '', name)
    # Remove the word "the"
    name = re.sub(r'\bthe\b', '', name)
    return name

# Preprocess and lemmatize company names
data1['processed_company']  = data1['company'].apply(preprocess_company_name)
#data1['lemmatized_company'] = data1['processed_company'].apply(lemmatize_company_name)
# Ensure consistency in the data by replacing any NaN or non-string values with an empty string
data2['Company_Name'] = data2['Company_Name'].fillna('').astype(str)
# Preprocess and lemmatize company names
data2['processed_company']  = data2['Company_Name'].apply(preprocess_company_name)

# Function to find the best match for each element in 'company' from 'company_names'
def find_best_match(company_name, threshold = 90):
    best_match = process.extractOne(company_name, data2['processed_company'], score_cutoff=threshold)
    if best_match is not None and best_match[1] > 90:
        return best_match[0]  # Return the best match if score is above 80
    else:
        return ''  # Return empty string if no match found or score is below 70

# 1. Applying the find_best_match function to find the matching result and storing it in data1['3']
data1['matched_company_name'] = data1['processed_company'].apply(find_best_match)
data1['matched_company_name']

# 2. Finding the position of the matching result in data2['lemmatized_company']
# Initialize an empty list to store the locations of matched company names
locations = []
# Iterate over the indices and company names in data1's 'matched_company_name' column
for index, company_name in data1['matched_company_name'].items():
    if company_name != '':
        # Find the index of the matched company name in data2's 'processed_company' column
        matched_index = data2[data2['processed_company'] == company_name].index
        if not matched_index.empty:
            locations.append(matched_index[0])
        else:
            locations.append(None)
    else:
        locations.append(None)

# Initialize columns to store matched company names and IDs
data1['Matched_Excel_Company_ID']=''
data1['matched_company_full_name']=''
# Iterate over each index and its corresponding location
for idx, location in enumerate(locations):
    if location is not None:
        # Assign the matched company full name and ID from data2 to data1
        data1.at[idx, 'matched_company_full_name'] = data2.at[location, 'Company_Name']
        data1.at[idx, 'Matched_Excel_Company_ID'] = data2.at[location, 'Excel_Company_ID']
    else:
        # If no match is found, assign empty strings to the matched company name and ID
        data1.at[idx, 'matched_company_full_name'] = ''
        data1.at[idx, 'Matched_Excel_Company_ID'] = ''
# Display the column containing matched company name IDs
data1['Matched_Excel_Company_ID']

# Remove columns 'processed_company', 'matched_company_name', and 'matched_company_full_name' from data1
data1.drop(columns=['processed_company','matched_company_name','matched_company_full_name'], inplace=True)

# Save matched data to CSV
data1.to_csv("Guangyao Zhou.csv", index=False)
